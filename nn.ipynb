{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'notebook'])\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticImagesGen:\n",
    "\n",
    "    def __init__(self, number_configs: int, training: list[str]=['all'], L=40):\n",
    "        if training == ['all']:\n",
    "            training = ['para', 'ferro', 'neel', 'stripe']\n",
    "        else:\n",
    "            training = [element.lower() for element in training]\n",
    "\n",
    "        self.number_configs = number_configs\n",
    "        self.training = training\n",
    "        self.L = L\n",
    "\n",
    "    def spin_gen(self, conf: str):\n",
    "        '''\n",
    "        Generates a spin configuration for the given configuration. \n",
    "        The resulting data is a tuple of the different configurations each one can have.\n",
    "        For example, ferromagnetic configurations can be spin up ferromagnetic or spin down ferromagnetic.\n",
    "        In this case, the tuple will contain two LxL matrices, one per each type.\n",
    "        '''\n",
    "        spin_conf = []\n",
    "        if conf == 'ferro':\n",
    "            spin_conf = [np.ones((self.L, self.L)).astype(int), \n",
    "                        -np.ones((self.L, self.L)).astype(int)]\n",
    "        elif conf == 'neel':\n",
    "            spin = np.fromfunction(lambda i, j: (-1)**(i + j + (conf == 4)), \n",
    "                                (self.L, self.L)).astype(int)\n",
    "            spin_conf = [spin, -spin]\n",
    "        elif conf == 'stripe':\n",
    "            spin = np.fromfunction(lambda i, j: (-1)**j, (self.L, self.L)).astype(int)\n",
    "            spin_conf = [spin, -spin, spin.T, -spin.T]\n",
    "        elif conf == 'para':\n",
    "            spin_conf = np.random.choice([-1, 1], size=(self.L, self.L)).astype(int)\n",
    "        return spin_conf\n",
    "    \n",
    "    def Info(self):\n",
    "        return print(f'Number of configurations: {self.number_configs}\\nTraining: {self.training} \\nL: {self.L}\\n')\n",
    "\n",
    "    def dataGenerator(self):\n",
    "        ''' \n",
    "        Generates synthetic data given a number of configurations and the type of training we want to do.\n",
    "        If 'all', then it will generate all possible configurations evenly distributed. There are 4 types of configurations.\n",
    "        If the number of configurations is not divisible by 4, the remaining configurations will be generated in a paramagnetic manner.\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        print(\"Generating synthetic data...\")\n",
    "        config_dict = {\n",
    "            'para': 1,\n",
    "            'ferro': 2,\n",
    "            'neel': 2,\n",
    "            'stripe': 4\n",
    "        }\n",
    "\n",
    "        labels_dict = {\n",
    "            'para': 0,\n",
    "            'ferro': 1,\n",
    "            'neel': 2,\n",
    "            'stripe': 3\n",
    "        }\n",
    "\n",
    "        selected_dict = {k: v for k, v in config_dict.items() if k in self.training}\n",
    "\n",
    "        selected_labels = {k: v for k, v in labels_dict.items() if k in self.training}\n",
    "        \n",
    "        total_configs_per_selected = self.number_configs // len(selected_dict.values())\n",
    "        remaining_configs = self.number_configs % len(selected_dict.values())\n",
    "\n",
    "        train_images = []\n",
    "        train_labels = []\n",
    "\n",
    "        if 'para' in self.training:\n",
    "            for _ in range(total_configs_per_selected):\n",
    "                train_images.append(self.spin_gen('para'))\n",
    "                train_labels.append(labels_dict['para'])\n",
    "            del selected_dict['para'], selected_labels['para']\n",
    "        \n",
    "        for conf in selected_dict:\n",
    "            total_conf = total_configs_per_selected\n",
    "            extra_configs = total_conf % selected_dict[conf]    \n",
    "                \n",
    "            if extra_configs !=0:\n",
    "                remaining_configs += extra_configs\n",
    "            \n",
    "            total_conf = total_conf // selected_dict[conf]\n",
    "\n",
    "            for _ in range(total_conf):\n",
    "                train_images.extend(self.spin_gen(conf))\n",
    "                for _ in range(config_dict[conf]):\n",
    "                    train_labels.append(labels_dict[conf])\n",
    "\n",
    "        if 'para' in self.training:\n",
    "            for _ in range(remaining_configs):\n",
    "                train_images.append(self.spin_gen('para'))\n",
    "                train_labels.append(labels_dict['para'])\n",
    "        else:\n",
    "            for i in range(remaining_configs):\n",
    "                index = i % len(self.training)\n",
    "                train_images.append(self.spin_gen(self.training[index])[0])\n",
    "                train_labels.append(labels_dict[self.training[index]])\n",
    "\n",
    "        temp = list(zip(train_images, train_labels))\n",
    "        random.shuffle(temp)\n",
    "        train_images, train_labels = zip(*temp)\n",
    "\n",
    "        print(\"Done!\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(\"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "        return np.array(train_images), np.array(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SyntheticImagesGen(10003, training=['ferro','neel','stripe'], L=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = data.dataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loader_and_saver:\n",
    "    def __init__(self, data, path,L: int=40):\n",
    "        self.data = data\n",
    "        self.path = path\n",
    "        self.L = L\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return np.load(os.path.join(self.path, f'array_{index}.npy'))   \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.path))   \n",
    "    \n",
    "    \n",
    "    def saver(self):\n",
    "        name = input(\"Enter the name of the file: \"/)\n",
    "        name += '.h5'\n",
    "        with h5py.File(name, 'w') as f:\n",
    "            for i, arr in enumerate(tqdm(self.data, desc=\"Saving images\", unit=\"array\")):\n",
    "                f.create_dataset(f'array_{i}', data=arr, compression='gzip', compression_opts=9)\n",
    "        print(\"Files saved!\")\n",
    "\n",
    "\n",
    "    def loader(self):\n",
    "        name = input(\"Enter the name of the file: \"/)\n",
    "        name += '.h5'\n",
    "        loaded_list = []\n",
    "        with h5py.File(name, 'r') as f:\n",
    "            for key in tqdm(sorted(f.keys(), key=lambda x: int(x.split('_')[1])), \n",
    "                            desc=\"Loading arrays\", unit=\"array\"):\n",
    "                loaded_list.append(f[key][:])\n",
    "        self.checker(self.data, loaded_list)\n",
    "        print(\"Files loaded!\")\n",
    "\n",
    "        return loaded_list\n",
    "\n",
    "    def checker(self, original_list, loaded_list):\n",
    "        data_is_equal = True\n",
    "        for original, loaded in zip(original_list, loaded_list):\n",
    "            if not np.array_equal(original, loaded):\n",
    "                data_is_equal = False\n",
    "                break\n",
    "        if data_is_equal:\n",
    "            print(\"The original data set and the loaded data set are identical.\")\n",
    "        else:\n",
    "            print(\"The original data set and the loaded data set are NOT identical.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulatedImages(indice, L=40):\n",
    "\n",
    "    print('loading...')\n",
    "\n",
    "    loadingPath = 'D:\\Facultad\\Doctorado\\Redes\\Datos\\simulacion L=40'\n",
    "\n",
    "    densityIndex = ['055','06', '061', '062', '063', '064', '065', '07', '08', '09','1']\n",
    "\n",
    "    c=251 # number of realizations in the average\n",
    "\n",
    "    density = densityIndex[indice]\n",
    "\n",
    "    indexList = []\n",
    "    \n",
    "    for i in range(c): # To control files. Example, file 'test_images_p1_L40_4.txt' does not exist.\n",
    "        controlPath = os.path.exists(os.path.join(loadingPath,f'test_images_p{density}_L40_{i}.txt'))\n",
    "        if controlPath == True:\n",
    "            indexList.append(i)\n",
    "\n",
    "    colnames=[\"red\",\"T\"]\n",
    "    data = []\n",
    "    simImages = []\n",
    "\n",
    "    for i in range(len(indexList)):\n",
    "        dataPath = os.path.join(loadingPath,f'test_images_p{density}_L40_{indexList[i]}.txt')  \n",
    "        df = pd.read_csv(dataPath, names=colnames, header=None)\n",
    "        df = df.iloc[::-1].reset_index(drop=True)\n",
    "        data.append(df)\n",
    "        simImages.append(np.array(data[i].loc[:,\"red\"]))\n",
    "        simImages[i] = simImages[i].reshape(251,L,L)   \n",
    "    \n",
    "    temperature = list(set(data[0].loc[:,\"T\"]))\n",
    "    temperature.sort() \n",
    "\n",
    "    print('data loaded.')\n",
    "    \n",
    "    return simImages, temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
